{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"Contents\"> Contents </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* <a href='#1'>**1 - Data Importing** </a>\n",
    "    * <a href='#1.01'>1.01 - Required Libraries </a>\n",
    "    * <a href='#1.02'>1.02 - Read in a CSV </a>\n",
    "    * <a href='#1.03'>1.03 - Read in a spreadsheet </a>\n",
    "    * <a href='#1.04'>1.04 - Read in a database </a>\n",
    "    \n",
    "\n",
    "* <a href='#2'>**2 - Quick Data Checks**</a>   \n",
    "    * <a href='#2.01'>2.01 - View the first X number of rows</a>\n",
    "    * <a href='#2.02'>2.02 - View the data type of each column</a>\n",
    "    * <a href='#2.03'>2.03 - View the quick stats of your numeric columns</a>\n",
    "    * <a href='#2.04'>2.04 - View the Shape (number of columns, number of rows)</a>\n",
    "    * <a href='#2.05'>2.05 - View count of non-NaN rows & dtype of each column</a>\n",
    "    \n",
    "    \n",
    "* <a href='#3'>**3 - Data Cleaning**</a>\n",
    "    * <a href='#3.01'>3.01 - Converting between data types</a>\n",
    "    * <a href='#3.02'>3.02 - Remove unwanted characters from a field & convert type</a>\n",
    "    * <a href='#3.03'>3.03 - Convert data type of Column - removing non-compliant data</a>\n",
    "    * <a href='#3.04'>3.04 - Replace missing values with 0</a>\n",
    "    * <a href='#3.05'>3.05 - Replace missing values with the mean</a>\n",
    "    * <a href='#3.06'>3.06 - Rename columns</a>\n",
    "    * <a href='#3.07'>3.07 - Create a brand new column</a>\n",
    "    * <a href='#3.08'>3.08 - Create a calculated column</a>\n",
    "    * <a href='#3.09'>3.09 - Drop columns</a>\n",
    "    * <a href='#3.10'>3.10 - Drop all rows containing at least 1 NaN</a>\n",
    "    * <a href='#3.11'>3.11 - Drop duplicates</a>\n",
    "    * <a href='#3.12'>3.12 - Cleaning date formats</a>\n",
    "    * <a href='#3.13'>3.13 - Removing or capping outliers</a>\n",
    "    * <a href='#3.14'>3.14 - Changing the index</a>\n",
    "    * <a href='#3.15'>3.15 - Converting character data into a series of 1/0 columns (one hot encoding)\n",
    "\n",
    "\n",
    "* <a href='#4'>**4 - Filtering & Sorting**</a>\n",
    "    * <a href='#4.01'>4.01 - Selecting specific columns</a>\n",
    "    * <a href='#4.02'>4.02 - Filtering on specific rows </a>\n",
    "    * <a href='#4.03'>4.03 - Remove filtered rows from DataFrame </a>\n",
    "    * <a href='#4.04'>4.04 - Remove rows with NaNs in a specific column </a>\n",
    "    * <a href='#4.05'>4.05 - Sorting the data </a>\n",
    "\n",
    "\n",
    "* <a href='#5'>**5 - Calculated statistics from columns**</a>\n",
    "    * <a href='#5.01'>5.01 - Basic summary statistics</a>\n",
    "    * <a href='#5.02'>5.02 - List all unique values</a>\n",
    "    * <a href='#5.03'>5.03 - Count the number of unique values</a>\n",
    "    * <a href='#5.04'>5.04 - Calculate the frequency for each unique value</a>\n",
    "\n",
    "\n",
    "* <a href='#6'>**6 - Visualisation**</a>\n",
    "    * <a href='#5.01'>5.01 - Visualising your Value Counts</a>\n",
    "    * <a href='#5.02'>5.02 - Visualise Value Counts, split by categories</a>\n",
    "    * <a href='#5.03'>5.03 - Pair Plots</a>\n",
    "    * <a href='#5.04'>5.04 - Histogram</a>\n",
    "    * <a href='#5.05'>5.05 - Boxplot - Single value</a>\n",
    "    * <a href='#5.06'>5.06 - Boxplot - Multiple Values</a>\n",
    "    * <a href='#5.07'>5.07 - Visualise with a scatterplot</a>\n",
    "\n",
    "\n",
    "* <a href='#7'>**7 - Aggregation and merging**</a>\n",
    "    * <a href='#7.01'>7.01 - Aggregating by a single column</a>\n",
    "    * <a href='#7.02'>7.02 - Aggregating by multiple columns</a>\n",
    "    * <a href='#7.03'>7.03 - Aggregating for multiple summary statistics at the same time</a>\n",
    "    * <a href='#7.04'>7.04 - Merging DataFrames on a single column</a>\n",
    "    * <a href='#7.05'>7.05 - Merging DataFrames on multiple columns</a>\n",
    "    * <a href='#7.06'>7.06 - Merging DataFrames on columns with different names</a>\n",
    "    \n",
    "    \n",
    "* <a href='#8'>**8 - Creating functions example**</a>\n",
    "    \n",
    "    \n",
    "* <a href='#9'>**9 - Plotting coordinates on a map**</a>\n",
    "    \n",
    "    \n",
    "* <a href='10'>**10 - Calculating distance between coordinates**</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - <a id='1'> Data Importing </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1.01'>1.01 - Import required libraries</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1.02'>1.02 - Read in a CSV </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can then tell Python where it should be looking (where the data is stored)\n",
    "os.chdir('C:\\\\Users\\\\Corndel PDE\\\\Data')\n",
    "\n",
    "# use to check file directory of where you're looking if import ever fails\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the most basic option to create a DataFrame (df) from a csv\n",
    "df = pd.read_csv('Donators.csv')\n",
    "\n",
    "# If the CSV has a natural id column then you can specify this within the parentheses\n",
    "# In this case we have specified that the first column (column 0) contains the index\n",
    "df = pd.read_csv('Donators.csv', index_col=0)\n",
    "\n",
    "# Sometimes it is helpful to specify the encoding of a file, such as when saved with UTF-8 encoding\n",
    "df = pd.read_csv('Donators.csv', index_col=0, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If reading in a CSV with dates and need to turn column into a date - dayfirst turns into DD/MM/YYYY\n",
    "pd.read_csv('data/data_1.csv', parse_dates=['date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use col_names to limit what columns to load\n",
    "col_names = ['STATEFIPS','STATE','zipcode','agi_stub','N1']\n",
    "tax_data_v1 = pd.read_csv('us_tax_data_2016.csv',usecols=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limiting rows\n",
    "tax_data_next500 = pd.read_csv('us_tax_data_2016.csv',\n",
    "nrows=500,\n",
    "skiprows=1000,\n",
    "header=None,\n",
    "names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying datatypes on upload\n",
    "tax_data = pd.read_csv(\"us_tax_data_2016.csv\", dtype={\"zipcode\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customising missing data values\n",
    "tax_data = pd.read_csv(\"us_tax_data_2016.csv\",na_values={\"zipcode\" : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines with errors \n",
    "#Set error_bad_lines=False to skip unparseable records\n",
    "#Set warn_bad_lines=True to see messages when records are skipped\n",
    "\n",
    "tax_data = pd.read_csv(\"us_tax_data_2016_corrupt.csv\",\n",
    "                        error_bad_lines=False,\n",
    "                        warn_bad_lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1.03'>1.03 - Read in a spreadsheet </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data = pd.read_excel(\"fcc_survey.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usecols to choose columns by name, positional number or letter e.g. \"A:P\"\n",
    "survey_data = pd.read_excel(\"fcc_survey_with_headers.xlsx\",\n",
    "skiprows=2,\n",
    "usecols=\"W:AB, AR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting sheets to use\n",
    "\n",
    "read_excel() loads the first sheet in excel file as default. Use the sheet_name keyword argument to load other sheets. The first sheet is always index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use either position index or name to pull in second sheet\n",
    "survey_data_sheet2 = pd.read_excel('fcc_survey.xlsx',sheet_name=1)\n",
    "survey_data_sheet2 = pd.read_excel('fcc_survey.xlsx',sheet_name=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sheet_name=None to read all sheets in a workbook\n",
    "survey_responses = pd.read_excel(\"fcc_survey.xlsx\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1.04'>1.04 - Read in a database </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sqlalchemy's create_engine() function to pull in data\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create the database engine - SQLiteURLformat:sqlite:///filename.db \n",
    "#i.e.\n",
    "engine = create_engine(\"sqlite:///data.db\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Load in data two ways via SQL Alchemy </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a table name to import all the data\n",
    "hpd_calls = pd.read_sql(\"hpd311calls\", engine)\n",
    "\n",
    "# Create a SQL query to load the entire weather table\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "  FROM weather;\n",
    "\"\"\"\n",
    "\n",
    "weather = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> You are able to use the standard operators to filters within a where clause, and select columns in usual sql way \n",
    "\n",
    "You can also use standard functions like distinct and aggregates \n",
    "\n",
    "\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it all together and you can use aggregation, joins and wheres\n",
    "query = \"\"\"SELECT \n",
    "hpd311calls.borough,\n",
    "COUNT(*),\n",
    "boro_census.total_population,\n",
    "boro_census.housing_units\n",
    "FROM hpd311calls\n",
    "JOIN boro_census ON hpd311calls.borough = boro_census.borough\n",
    "GROUP BY hpd311calls.borough;\"\"\"\n",
    "\n",
    "call_counts = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#Contents\">_Return to Contents_</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='2'>2 - Quick Data Checks</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2.01'>2.01 - View the first X number of rows </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is always helpful to use the head() method to look at the first few rows of your DataFrame\n",
    "# You can also specify how many rows you want to see but you don't have to\n",
    "# We have asked for 7 rows to be returned\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2.02'>2.02 -  View the data type of each column </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type (dtype) for each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2.03'>2.03 - View the quick stats of your numeric columns  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe method provides various summary statistics for all *numeric* columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2.04'>2.04 -   View the Shape (number of rows, number of columns) </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the shape of the DataFrame (columns + rows)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2.05'>2.05 -   View count of non-NaN rows & dtype of each column </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The info method provides less detailed information about ALL columns\n",
    "# It tells us the number of non-NaN values and dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#Contents\">_Return to Contents_</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='3'>3 - Data Cleaning</a>\n",
    "\n",
    "## <a id='3.01'>3.01 - Converting between data types </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might want to change the dtype of a numeric column to string\n",
    "df['smiley_rating'] = df['smiley_rating'].astype(str)\n",
    "\n",
    "# We might want to change the dtype of a string or object to a numeric type (integer or float)\n",
    "# In this case we will change the smiley rating back to a float\n",
    "df['smiley_rating'] = df['smiley_rating'].astype(float)\n",
    "\n",
    "# Or we can try to make it an integer!\n",
    "# But this *does not work* on this dataset because the column contains NaNs and int columns cannot\n",
    "df['smiley_rating'] = df['smiley_rating'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.02'>3.02 - Remove unwanted characters from a field & convert type </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the replace function to replace the unwanted character with blank\n",
    "# Here we replace '£' with nothing so that it is removed from the column\n",
    "df['donation'] = df['donation'].replace({'\\£':''}, regex=True)\n",
    "\n",
    "# We use the .astype() function to set it to a float! (once the unwanted characters have been removed)\n",
    "df['donation'] = df['donation'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.03'>3.03 - Convert data type of column - removing non-compliant data </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This removes anything that isn't a number and converts the field to a number\n",
    "# They will become Float64, as an Int field can not contain NaNs\n",
    "df['number_of_younger_siblings'] = df['number_of_younger_siblings'].apply(pd.to_numeric, errors='coerce')\n",
    "df['number_of_older_siblings'] = df['number_of_older_siblings'].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.04'>3.04 - Replace missing values with 0 </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This fills any NaNs with 0. You could put any value in the brackets of fillna to put that value in instead.\n",
    "df['number_of_younger_siblings'] = df['number_of_younger_siblings'].fillna(0)\n",
    "df['number_of_older_siblings'] = df['number_of_older_siblings'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can now convert these cells to be integers, as they contain no more NaNs\n",
    "df['number_of_younger_siblings'] = df['number_of_older_siblings'].astype(int)\n",
    "df['number_of_older_siblings'] = df['number_of_older_siblings'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.05'>3.05 - Replace missing values with the mean </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean\n",
    "smiley_mean = df['smiley_rating'].mean()\n",
    "\n",
    "# Replace missing values with the mean\n",
    "df['smiley_rating'] = df['smiley_rating'].fillna(smiley_mean)\n",
    "\n",
    "# We can now convert Smiley Rating to an int as it contains no NaNs\n",
    "df['smiley_rating'] = df['smiley_rating'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.06'>3.06 -  Rename columns  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remane all the columns simply by listing the new names we want\n",
    "smiley_summary.columns = ['meeting_time','donations','first_name', ... etc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we make a *mapping* of the OLD:NEW column names in a dictionary\n",
    "column_map = {'number_of_younger_siblings':'younger_siblings',\n",
    "              'number_of_older_siblings':'older_siblings'}\n",
    "\n",
    "# Use the rename() method to name\n",
    "df = df.rename(columns = column_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.07'>3.07 - Create a brand new column </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a new column, you simply put the name your new column and say what it is equal to.\n",
    "# This creates a new column called 'new_column' and sets it to equal to True\n",
    "df['new_column'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.08'>3.08 - Create a calculated column </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps we want to create a column called 'total siblings'\n",
    "df['total_siblings'] = df['younger_siblings'] + df['older_siblings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we might create a column which takes a different value...\n",
    "# ... depending on whether the smiley_rating is greater than a certain value\n",
    "df['nice_person'] = np.where(df['smiley_rating'] > 5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.09'>3.09 - Drop columns </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check what columns we have and print the list of columns\n",
    "all_cols = list(df.columns)\n",
    "print(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make a list of columns you would like to remove\n",
    "## They need to match exactly (you can copy and paste from the printed list above!)\n",
    "unwanted_cols = ['first_name', 'last_name', 'new_column', 'nice_person']\n",
    "print(unwanted_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we drop them!\n",
    "df = df.drop(columns=unwanted_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.10'> 3.10 - Drop all rows containing at least 1 NaN </a>\n",
    "###### (use with caution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A better approach is to only drop rows which have NaNs for specific columns (and ignore NaNs in other columns)\n",
    "# This will only drop rows where there are NaNs for the 'smiley_rating' columns\n",
    "df = df.dropna(subset=['smiley_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.11'>3.11 - Drop duplicates </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Subset is which Columns should be considered.\n",
    "# If you're looking for duplicates rows that have the same value in every column, you can use subset=None\n",
    "# Otherwise list the columns as a list. subset=['column1', 'column2']\n",
    "df = df.drop_duplicates(subset=None, keep='first')\n",
    "\n",
    "# Or this version will drop all duplicates where *both* first name and last name are the same across two records\n",
    "df = df.drop_duplicates(subset=['older_siblings','younger_siblings'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.12'>3.12 - Cleaning date formats </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specifying the right value for the 'format' argument is extremely important\n",
    "df['meeting_date'] = pd.to_datetime(df['meeting_date'], format='%d/%m/%Y', errors='ignore')\n",
    "\n",
    "# If we only want the *time* part then we would add .dt.time to the end of the code\n",
    "# This line of code below does not work as the information in the dataset is data information (not time)\n",
    "df['meeting_time'] = pd.to_datetime(df['meeting_time'],format= \"%H:%M %p\" ).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You may need to change the 'format' argument to something else\n",
    "# <your column> = pd.datetime(<your column>, format='<date format>', errors='ignore')\n",
    "\n",
    "#    %y :    2-digit year\n",
    "#    %Y :    4-digit year\n",
    "#    %m :    month\n",
    "#    %d :    day\n",
    "#    %H :    hour\n",
    "#    %M :    minute\n",
    "#    %S :    second\n",
    "#    %p :    AM or PM\n",
    "\n",
    "# Note that there is a difference between 21/09/1996 = '%d/%m/%Y'\n",
    "#                                     and 21-09-1996 = '%d-%m-%Y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.13'>3.13 - Removing or capping outliers </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could either remove the outliers\n",
    "df = df[df['donation'] < 600]\n",
    "\n",
    "# Or we could cap the outliers at a reasonable value\n",
    "# Here we use the np.where() function to change the value to 100 whenever it is larger than 100\n",
    "df['donation'] = np.where(df['donation'] > 100, 100, df['donation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.14'>3.14 - Changing the index </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index is the \"column\" on the far left of the DataFrame\n",
    "# Sometimes the title is lower than all the other columns headings\n",
    "\n",
    "# For the Donations dataset the index is called 'id', your data might have an unnamed index\n",
    "df['new_column_from_index'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also 'reset' the index\n",
    "# This will insert the current index as a column and make a new index starting from 0\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can choose an existing column and make it the index\n",
    "# *As long as* ... all the values in the column are unique (in an index all values must be unique)\n",
    "\n",
    "# The code below takes the column create by the reset_index() method (see above)\n",
    "# And makes it the index again\n",
    "df = df.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.15'>3.15 - Converting character data into a series of 1/0 columns (one hot encoding) </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the column only has a small number of unique values then it is relatively simple\n",
    "df['male_flag'] = np.where(df['gender'] == 'Male', 1, 0)\n",
    "df['female_flag'] = np.where(df['gender'] == 'Female', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But for the 'favourite_cake' column we have quite a few possible values\n",
    "print(df['favourite_cake'].unique())\n",
    "\n",
    "# We can use a for loop to create a 1/0 flag for every unique value\n",
    "for x in list(df['favourite_cake'].unique()):\n",
    "    df[str(x)+' flag'] = np.where(df['favourite_cake'] == str(x), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#Contents\">_Return to Contents_</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='4'>4 - Filtering & Sorting  </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4.01'>4.01 - Selecting specific columns </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict the data to only some selected columns\n",
    "df_four_columns = df[['donation','gender','younger_siblings','older_siblings']]\n",
    "\n",
    "# If we wanted to permanently only select those columns, we would assign it back to the same dataframe\n",
    "# with df = df[['col1', 'col2'...]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4.02'>4.02 - Filtering on specific rows </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to filter the data so that we only have records where 'smiley_rating' is 6\n",
    "only_smiley_6 = df[df['smiley_rating'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to combine two conditions then we can use\n",
    "# either the 'and' sign (&) or the 'or' sign (|)\n",
    "only_smiley_5or6 = df[(df['smiley_rating'] == 6) | (df['smiley_rating'] == 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could also have achieved this last result by using the isin() method\n",
    "only_smiley_5or6 = df[df['smiley_rating'].isin([5,6])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4.03'>4.03 - Remove filtered rows from the DataFrame </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We simply assign the filtered result back to the original dataframe\n",
    "# This will remove the ones that do not meet the requirement\n",
    "df = df[df['smiley_rating'] < 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4.04'>4.04 - Remove rows with NaNs in a specific column </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select everything that is not an NaN in that column, and assign it back to the original dataframe\n",
    "df = df[df['gender'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4.05'>4.05 - Sorting the data </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To sort the data we use the sort_values() method\n",
    "sorted_df = df.sort_values('donation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To sort in descending order\n",
    "sorted_df = df.sort_values('donation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To sort based on two or more columns (not just one)\n",
    "sorted_df = df.sort_values(['favourite_pet','donation'], ascending=[True,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='5'>5 - Calculated statistics from columns </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='5.01'>5.01 - Basic summary statistics </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate most basic statistics for columns\n",
    "# using either Pandas methods or Numpy functions\n",
    "\n",
    "# COUNT (NON-NULLS)\n",
    "df['smiley_rating'].count()\n",
    "len(df['smiley_rating'])\n",
    "\n",
    "# SUM\n",
    "df['smiley_rating'].sum()\n",
    "np.sum(df['smiley_rating'])\n",
    "\n",
    "# MEAN\n",
    "df['smiley_rating'].mean()\n",
    "np.mean(df['smiley_rating'])\n",
    "\n",
    "# MEDIAN\n",
    "#df['smiley_rating'].median()#\n",
    "#np.median(df['smiley_rating'])\n",
    "\n",
    "# STANDARD DEVIATION\n",
    "df['smiley_rating'].std()\n",
    "np.std(df['smiley_rating'])\n",
    "\n",
    "# MIN\n",
    "df['smiley_rating'].max()\n",
    "np.max(df['smiley_rating'])\n",
    "\n",
    "# MAX\n",
    "df['smiley_rating'].min()\n",
    "np.min(df['smiley_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='5.02'>5.02 - List all unique values </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can list all the unique values in a columns\n",
    "df['smiley_rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='5.03'>5.03 - Count the number of unique values </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can count the number of unique values (in two ways)\n",
    "df['smiley_rating'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='5.04'>5.04 - Calculate the frequency for each unique value </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can return all the unique values and see how often they occur\n",
    "df['smiley_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to convert this into a DataFrame (perhaps so we can merge it later)\n",
    "smiley_rating_counts = pd.DataFrame(df['smiley_rating'].value_counts())\n",
    "\n",
    "# As before (in the indexes section) we can make the index into a column\n",
    "# We will also change the names of the columns to be a bit more meaningful\n",
    "smiley_rating_counts = pd.DataFrame(df['smiley_rating'].value_counts())\n",
    "smiley_rating_counts = smiley_rating_counts.reset_index()\n",
    "smiley_rating_counts.columns = ['smiley_rating','frequency']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#Contents\">_Return to Contents_</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='6'>6 - Visualisation </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='6.01'>6.01 - Visualising your Value Counts </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the favourite_pet value counts\n",
    "bc = df['favourite_pet'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='6.02'>6.02 - Visualise Value Counts, split by categories </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = df.groupby(['favourite_pet','gender']).count()['donation'].unstack().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='6.03'>6.03 - Pair Plots </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplots = pd.plotting.scatter_matrix(df, figsize=(15, 15), marker='o',\n",
    "                        hist_kwds={'bins': 20}, s=60, alpha=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='6.04'>6.04 - Histogram </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg = df['donation'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='6.05'>6.05 - Boxplot - Single value </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = df[['donation']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='6.06'>6.06 - Boxplot - Multiple Values </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = df[['smiley_rating', 'older_siblings']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='6.07'>6.07 - Visualise with a scatterplot  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = df.plot.scatter('donation', 'smiley_rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.08 - Create time series plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function called plot_timeseries\n",
    "def plot_timeseries(axes, x, y, color, xlabel, ylabel):\n",
    "\n",
    "  # Plot the inputs x,y in the provided color\n",
    "  axes.plot(x, y, color=color)\n",
    "\n",
    "  # Set the x-axis label\n",
    "  axes.set_xlabel(xlabel)\n",
    "\n",
    "  # Set the y-axis label\n",
    "  axes.set_ylabel(ylabel, color=color)\n",
    "\n",
    "  # Set the colors tick params for y-axis\n",
    "  axes.tick_params('y', colors=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the CO2 levels time-series in blue\n",
    "plot_timeseries(ax, climate_change.index, climate_change['co2'], \"blue\", \"Time (years)\", \"CO2 levels\")\n",
    "\n",
    "# Create a twin Axes object that shares the x-axis\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Plot the relative temperature data in red\n",
    "plot_timeseries(ax, climate_change.index, climate_change['relative_temp'], \"red\", \"Time (years)\", \"Relative temperature (Celsius)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#Contents\">_Return to Contents_</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='7'>7 - Aggregation and merging </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='7.01'>7.01 - Aggregating by a single column  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by works very similarly to the GROUP BY command in SQL\n",
    "# We choose which column we want to use to aggregate ('smiley_rating')\n",
    "# And specify which column we are interested in summarising ('total_siblings')\n",
    "# And how we want to summarise it ('mean')\n",
    "df.groupby('smiley_rating')['total_siblings'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can convert this into a DataFrame and rename the columns\n",
    "smiley_summary = df.groupby('smiley_rating')['total_siblings'].mean()\n",
    "smiley_summary = smiley_summary.reset_index()\n",
    "smiley_summary.columns = ['smiley_rating','average_number_of_siblings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='7.02'>7.02 - Aggregating by multiple columns  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to aggregate by two or more columns\n",
    "df.groupby(['gender','favourite_pet'])['total_siblings'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='7.03'>7.03 - Aggregating for multiple summary statistics at the same time  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is also possible to apply several different statistics to different columns\n",
    "# Based on the same aggregating column\n",
    "df.groupby('smiley_rating').agg({'younger_siblings': ['mean', 'count'],\n",
    "                                 'total_siblings': ['median', 'min', 'count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='7.04'>7.04 - Merging DataFrames on a single column  </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Before merging we will need to create two DataFrames that we can merge together.</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = df[df['smiley_rating'] == 2][['first_name','last_name','favourite_pet','smiley_rating','favourite_cake']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = df[df['smiley_rating'] == 1][['first_name','last_name','favourite_pet','smiley_rating','favourite_cake']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN ON A SINGLE COLUMN\n",
    "table1.merge(table2, on='favourite_pet', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='7.05'>7.05 - Merging DataFrames on multiple columns  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNER JOIN ON TWO COLUMNS\n",
    "table1.merge(table2, on=['favourite_pet','favourite_cake'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='7.06'>7.06 - Merging DataFrames on columns with different names  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN ON TWO COLUMNS WHICH DO NOT HAVE THE SAME NAME AS EACH OTHER\n",
    "table1.merge(table2, left_on='favourite_pet', right_on='favourite_cake', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>As it stands, this last join will not return any results because 'favourite_pet' never equals 'favourite_cake'!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='8'>8 - Creating functions example  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the area of a trapezium\n",
    "def trapezium_area(width1, width2, height):\n",
    "    average_width = (width1 + width2) / 2\n",
    "    area = average_width * height\n",
    "    return (area)\n",
    "\n",
    "# Call the function several times for different widths and heights\n",
    "print(trapezium_area(4, 6, 1))\n",
    "print(trapezium_area(4, 6, 2))\n",
    "print(trapezium_area(5, 6, 1))\n",
    "print(trapezium_area(5, 6, 2))\n",
    "print(trapezium_area(4, 4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='9'>9 - Plotting coordinates on a map  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/easy-steps-to-plot-geographic-data-on-a-map-python-11217859a2db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='10'>10 - Calculating distance between coordinates  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> df['distance'] = haversine_np(df['lon1'],df['lat1'],df['lon2'],df['lat2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mss['Month'] = pd.to_datetime(mss['Month'], format='%Y-%m', errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Time Series - ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Auto Arima\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "model = auto_arima(ts.ABC_Sales,trace=True,error_actions='ignore')\n",
    "\n",
    "model.fit(ts.ABC_Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a model with order (2,1,3)\n",
    "model = ARIMA(ts['ABC_Sales'], order=(2,1,3), freq='D')\n",
    "model_fit = model.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create space for two plot at the same time\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,4))\n",
    "# Use the plot_predict method to fit model and forecast into the future\n",
    "model_fit.plot_predict(1, 425, ax=ax[0])\n",
    "model_fit.plot_predict(250, 350, ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#Contents\">_Return to Contents_</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
